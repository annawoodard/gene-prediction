{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import parsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x2aab119a3be0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aspire import config\n",
    "parsl.load(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "chunk_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_normalize(df):\n",
    "    \"\"\"\n",
    "    see https://stackoverflow.com/questions/37935920/quantile-normalization-on-pandas-dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    rank_mean = df.stack().groupby(df.rank(method='first').stack().astype(int)).mean()\n",
    "    \n",
    "    return df.rank(method='min').stack().astype(int).map(rank_mean).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download expression data from archs4**\n",
    "\n",
    "For more info: https://amp.pharm.mssm.edu/archs4/help.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://s3.amazonaws.com/mssm-seq-matrix/human_matrix.h5\"\n",
    "if not os.path.isfile(os.path.basename(url)):\n",
    "    urllib.request.urlretrieve(url, os.path.basename(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('human_matrix.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = file['meta']['Sample_geo_accession']\n",
    "tissue = file['meta']['Sample_source_name_ch1']\n",
    "genes = list(x.decode() for x in file['meta']['genes'])\n",
    "data = pd.DataFrame(file['data']['expression'][:num_samples], columns=genes) # data has sample rows and gene columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = {}\n",
    "with open('libraries/KEGG_2015.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        library[parts[0]] = [x.strip() for x in parts[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a gene does not appear in any gene set, the ROC is undefined\n",
    "# i'm not sure if we should be using sklearn.metrics.roc_auc_score or sklearn.metrics.auc\n",
    "genes = list(set(sum(library.values(), [])).intersection(genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = quantile_normalize(data[genes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@parsl.python_app\n",
    "def calculate_auc(gene_chunk, genes, library, normalized_data):\n",
    "    import pandas as pd\n",
    "    import sklearn.metrics\n",
    "    \n",
    "    G = pd.DataFrame(index=gene_chunk, columns=library.keys())\n",
    "    GM = pd.DataFrame(index=gene_chunk, columns=library.keys())\n",
    "    result = []\n",
    "    for gene in gene_chunk:\n",
    "        for gene_set in library:\n",
    "            intersection = set(library[gene_set] + [gene]).intersection(genes)\n",
    "            correlation = normalized_data[intersection].corr().loc[gene]\n",
    "            GM.loc[gene, gene_set] = correlation[correlation.index != gene].mean()\n",
    "            G.loc[gene, gene_set] = 1 if gene in library[gene_set] else 0\n",
    "            \n",
    "        true = G.loc[gene].values.astype(int)\n",
    "        score = GM.loc[gene].values.astype(float)\n",
    "        result += [sklearn.metrics.roc_auc_score(true, score)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8848a8d230184148b5f3d7255027004b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=126), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc = []\n",
    "chunks = [genes[x:x + chunk_size] for x in range(0, len(genes), chunk_size)]\n",
    "for gene_chunk in tqdm.tqdm_notebook(chunks):\n",
    "    auc += [calculate_auc(gene_chunk, genes, library, normalized_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc[0].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_tasks = lambda x: sum([i.result() for i in x if i.done()], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=completed_tasks(auc), orient='v', width=0.6)\n",
    "ax.set_ylabel('AUC')\n",
    "ax.set_aspect(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('median AUC: {:.3f}'.format(np.median(completed_tasks(auc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ax.get_figure()\n",
    "fig.savefig('auc.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
